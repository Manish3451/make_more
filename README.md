# 🧠 MakeMore — Zero-to-Hero Neural Network

[![Python](https://img.shields.io/badge/python-3.9%2B-blue.svg)](https://www.python.org/)  
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)  
[![Build Status](https://img.shields.io/badge/build-passing-brightgreen.svg)](#)  
[![Made with Love](https://img.shields.io/badge/made%20with-%E2%9D%A4-red)](#)

This project is inspired by **Andrej Karpathy’s Zero-to-Hero** series and implements the **MakeMore character-level language model** from scratch.  
It walks through the full lifecycle: data preparation → model training → inference → deployment → monitoring.  

---

## 📌 Features
- End-to-end training loop (dataset → preprocessing → training → evaluation)
- Character-level neural network for text generation
- Configurable experiments with checkpoints and logging
- Model registry for versioning
- Deployment ready (API serving or batch inference)
- MLOps integration (monitoring, CI/CD)

---

## 📂 Project Structure
makemore/
│── data/ # raw datasets
│── notebooks/ # exploratory notebooks
│── src/
│ ├── preprocessing/ # tokenizers, normalization
│ ├── models/ # neural network architectures
│ ├── training/ # training loops, optimizers
│ ├── serving/ # API / batch inference
│ ├── utils/ # helpers
│── tests/ # unit tests
│── requirements.txt # dependencies
│── README.md # project documentation


---

## 🔧 Setup

```bash
# Clone repo
git clone https://github.com/yourusername/makemore.git
cd makemore

# Create environment
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
🚀 Training the Model
python src/training/train.py --config configs/baseline.yaml


Options:

--epochs : number of training epochs

--lr : learning rate

--batch-size : batch size

--save-dir : output directory

📊 High-Level System Diagram
flowchart LR
  subgraph Data
    A[Raw Data (text/images/metadata)] --> B[Preprocessing]
  end

  B --> C[Feature Store]
  C --> D[Training Pipeline]
  D --> E[Model Registry]
  E --> F[Deployment (API / Batch / Edge)]
  F --> G[Users / Clients]
  G --> H[Feedback Loop]
  H --> B

  subgraph MLOps
    E --> I[CI/CD]
    I --> F
    F --> J[Monitoring & Logging]
    J --> K[Alerting]
    K --> I
  end

📈 Training Pipeline (Detailed)
sequenceDiagram
  participant DS as Data Source
  participant PP as Preprocessing
  participant FS as Feature Store
  participant TP as Training Pipeline
  participant MM as Model Manager
  participant MR as Model Registry

  DS->>PP: emit raw data
  PP->>FS: store clean features
  FS->>TP: batch features + labels
  TP->>TP: train model (epochs)
  TP->>MM: save checkpoints
  MM->>MR: register final model + metadata

⚡ Inference & Serving
flowchart TD
  Client -->|request| API[Model API Gateway]
  API --> Router[Request Router]
  Router -->|sync| SyncSrv[Sync Inference Service]
  Router -->|async| Queue[Message Queue]
  Queue --> Worker[Batch/Async Worker]

  SyncSrv --> ModelCache[Model Cache / Fast Model]
  Worker --> ModelStore[Model Store]
  ModelCache --> ModelStore
  ModelStore --> FeatureStore[Feature Store]
  FeatureStore --> Preproc[On-request Preproc]
  Preproc --> Model
  Model --> Postproc[Postprocessing]
  Postproc --> Client

🛠️ Running Inference
python src/serving/infer.py --text "Andrej"


Outputs a continuation generated by the model.

🔄 CI/CD Workflow
flowchart LR
  Git[Git Repo] --> CI[CI Pipeline]
  CI --> Test[Unit + Integration + Model Tests]
  Test --> Build[Build Artifacts]
  Build --> CD[CD Pipeline]
  CD --> Staging[Staging Deploy]
  Staging --> Smoke[Smoke Tests]
  Smoke --> Prod[Prod Deploy]
  Prod --> Monitor[Monitoring]
  Monitor --> Rollback[Rollback if issues]
  Rollback --> Git

📡 Monitoring

Latency monitoring: API response times

Data drift detection: check input distribution shift

Model performance: log accuracy/perplexity

Alerting: Slack/email alerts on anomalies

📝 Roadmap

 Add Transformer-based architecture

 Hyperparameter tuning with Optuna

 Batch + Streaming inference pipelines

 Integration with MLflow for experiment tracking

🤝 Contributing

Pull requests are welcome! For major changes, open an issue first to discuss what you’d like to change.

📜 License

MIT
